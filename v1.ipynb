{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №3\n",
    "## Задание №1\n",
    "Скачайте текст [\"Литературных анекдотов\"](https://github.com/ancatmara/python-for-dh/blob/master/Classes/9-10/literary_anecdotes.txt) . Напишите функцию, которая будет читать файл, лемматизировать текст с помощью pymystem3 и записывать результат в новый файл. \n",
    "У функции должно бы два аргумента: путь к исходному файлу и путь к файлу с лемматизированным текстом. Вызов функции тоже должен быть прописан в решении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import os\n",
    "import re\n",
    "os.chdir('C:\\\\Users\\\\User\\\\Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmitize(input_txt, output_txt):\n",
    "    with open(input_txt, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        m = Mystem()\n",
    "        lemmas = m.lemmatize(text)\n",
    "    g = open(output_txt, 'tw', encoding='utf-8')\n",
    "    g.write(''.join(lemmas))\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmitize('literary_anecdotes.txt','text.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №2\n",
    "Очистите лемматизированный текст от стоп-слов и посчитайте ipm для оставшихся. Выведите 20 самых частотных по этому параметру слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rus_stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    stops = file.read()\n",
    "    words = stops.split()\n",
    "    with open('text.txt', 'r', encoding='utf-8') as file1:\n",
    "        text = file1.read()\n",
    "        final_text = re.sub('\\W',' ',text)\n",
    "        list1 = final_text.split()\n",
    "        for word in words:\n",
    "            for text_word in list1:\n",
    "                if (word==text_word):\n",
    "                    list1.remove(text_word)\n",
    "set1 = set(list1)\n",
    "count = len(list1)\n",
    "d = dict()\n",
    "for set_word in set1:\n",
    "    d[set_word]=list1.count(set_word)/ count * 1000000\n",
    "sorted_d = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_d[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №3\n",
    "Сделайте полный морфологический разбор исходного текста. Напишите регулярное выражение, которое будет извлекать из тега только часть речи. Пройдитесь циклом по списку с разборами, который выдал pymystem3, извлекая из каждого разбора форму слова и его часть речи и записывая их в новый словарь (форма -- ключ, часть речи -- значение). Посчитайте абсолютную частоту для всех частей речи, а затем относительнную частоту (абсолютная частота / длина текста в словах)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text0 = text.split()\n",
    "list2 = list()\n",
    "for words2 in text0: \n",
    "    list2.append(m.analyze(words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 =dict()\n",
    "for words3 in list2:\n",
    "#    re.match('/.*\\=)','res[0]['analysis'][0]['gr']')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
